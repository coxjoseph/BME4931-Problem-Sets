{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154f2731-5f64-4c2e-9d91-1eb1db1ca106",
   "metadata": {},
   "source": [
    "# Module 9 Problem Set\n",
    "Problem Set for Module 9 - CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a562ee9-349a-4852-9e2a-2be089c81eb7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this Problem Set, we will discuss the creation of Convolutional Neural Networks (CNNs). We will use the `tensorflow` library for creating our CNN, though if you are familiar with Pytorch, you will find the methods used here to be readily applicable through `torch.nn.sequential`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a890a1f-ad3f-4b2f-a243-fabc39952a76",
   "metadata": {},
   "source": [
    "## Data\n",
    "As the problems we have get more complex, the datasets we apply our problems to get similarly complex. In your own endeavours (e.g. homework), you will notice that suitable data is a bit harder to come by compared to our simpler models like KNN and Decision Trees. Suitable data for CNNs will more often than not involve images. **This is because CNN's work best with data with spatial features. In other words, the input to a CNN is best suited for spatially organized data like images. Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac481e-7157-4149-b9b2-76c8736e023c",
   "metadata": {},
   "source": [
    "[Type here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8dcf9-0c40-447f-a479-8b0ca46e7c72",
   "metadata": {},
   "source": [
    "Often, especially with medical data, you will need to sign a licensing agreement to deal with real data. Moreover, these datasets will often require a lot of storage to deal with (more than GitHub would be happy with me uploading). Because of this limitiation, this problem set tackles one of the more \"typical\" CNN datasets - the MNIST digits dataset. \n",
    "\n",
    "The MNIST handwritten digits dataset is a widely used benchmark in machine learning, containing a collection of 28x28 pixel grayscale images of handwritten digits (0 through 9). It consists of 60,000 training images and 10,000 testing images, with each image depicting a single digit written by various individuals. \n",
    "\n",
    "Fortunately for us, tensorflow (and pytorch as well) has an instance of this dataset built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476c4d4-569b-416a-ad9a-8e81147e59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "tf.random.set_seed(3621)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Exploring the dataset\n",
    "print(f\"Shape of training images: {x_train.shape}\")\n",
    "print(f\"Shape of testing images: {x_test.shape}\")\n",
    "print(f\"Number of classes: {len(set(y_train))}\")  # The built-in set type works exactly like sets in math - a list with no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a1030-f246-44d8-bd15-8ac06168d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary to group images by their class (digit)\n",
    "class_images = {i: [] for i in range(10)}\n",
    "\n",
    "# Populate the dictionary with images\n",
    "for i in range(len(x_train)):\n",
    "    class_label = y_train[i]\n",
    "    class_images[class_label].append(x_train[i])\n",
    "\n",
    "# Plot a few examples from each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(class_images[i][0], cmap='gray')  # Display the first image of each class\n",
    "    plt.title(f\"Class {i}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612095b-e910-4c3f-b89b-44318fb142a9",
   "metadata": {},
   "source": [
    "**With the information and output from cells above, describe the task of our CNN - what are we trying to do? Is this classification or regression? What are suitable loss functions/error metrics for training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b83d1-7036-4c36-9f86-414b4eba8444",
   "metadata": {},
   "source": [
    "[Type here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce53d8-a067-45d2-a811-5556128b7e10",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1fa29a-3172-4508-953b-9eaaad809933",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32f8d3-cac4-4138-9ce7-3916118ce1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Preprocess the data\n",
    "## Input data (images): make sure all data is 28x28x1 arrays with datatype float32 (32 bit float)\n",
    "##             and scale by 255 (max value for any pixel) so that all input is in between 0 and 1.\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0 \n",
    "## Targets (classes): one-hot encode by using the to_categorical function\n",
    "y_train = to_categorical(y_train, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a8fab-239b-4323-bfbc-adbafe1eedca",
   "metadata": {},
   "source": [
    "**Do we need to perform the same preprocessing steps to our testing data? Only some of the steps? Explain your answer? If preprocessing is necessary, use the following cell to preprocessing the testing data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825eb84-ad78-456c-acad-f232d502234f",
   "metadata": {},
   "source": [
    "[Type here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f3a0e-afc7-4571-9b49-0bbc16934221",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0fa07-4a80-4275-b387-7bb249af49d1",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056c5da-7330-4636-ac9a-81a5ce3e8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Create a simple CNN model\n",
    "## Start with tensorflow.keras.models.Sequential()\n",
    "model = models.Sequential()\n",
    "\n",
    "#Proceed to add layers with models.add()\n",
    "## Unlike pytorch, tensorflow will \n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))  # 32 filters, 3x3 kernels\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85287b-bc10-449e-91f9-0a34ee27985b",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "The cell below compiles our model (in other words, finalizes its shape) and then fits the model to our data over 5 epochs. **However, *something is wrong with the code* - what is it? Before running the code, implement a fix for this problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7c07c-7ffd-4c59-86ad-7c708d7b5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e5abd-5757-4d99-9202-14d76774afef",
   "metadata": {},
   "source": [
    "[Type here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa0804-7cfd-4b8f-898c-0653bf35bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2c7bd-7129-467f-8b7f-30e8575eed9d",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba0e1c-ae28-4937-a7e8-f040201ab6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6052a-b914-4f95-8e9b-9d9207268835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Find misclassified images\n",
    "misclassified_indices = np.where(np.argmax(predictions, axis=1) != np.argmax(y_test, axis=1))[0]\n",
    "\n",
    "# Visualize 5 correct predictions\n",
    "n_examples = 5 \n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(n_examples):\n",
    "    plt.subplot(2, n_examples, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    actual_label = np.argmax(y_test[i])\n",
    "    predicted_label = np.argmax(predictions[i])\n",
    "    plt.title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\") \n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualize 5 incorrect predictions if they exist\n",
    "n_examples = min(5, len(misclassified_indices)) \n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(n_examples):\n",
    "    index = misclassified_indices[i]\n",
    "    plt.subplot(2, n_examples, i + 1)\n",
    "    plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "    actual_label = np.argmax(y_test[index])\n",
    "    predicted_label = np.argmax(predictions[index])\n",
    "    plt.title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\", color='red')  # Highlight misclassifications in red\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183c30e-074e-434c-a7bd-2ad126420530",
   "metadata": {},
   "source": [
    "**Evaluate our model? Does it perform well? Are there things we could do to improve its performance or tweak our model? Give some concrete examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cbe96-6af4-418d-9528-07c584aff24f",
   "metadata": {},
   "source": [
    "[Type here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8be2d6-90b0-44e7-b4a6-43a3b6e0ed93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
