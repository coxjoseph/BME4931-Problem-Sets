{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9020fff1",
   "metadata": {},
   "source": [
    "# Problem Set 10 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220c2bf",
   "metadata": {},
   "source": [
    "This code covers the implementation of a Long Short-Term Memory (LSTM) architecture. Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) architecture designed to address the vanishing gradient problem in standard RNNs. It is particularly well-suited for processing sequences of data, making it a popular choice for tasks such as time series analysis, natural language processing, and more.\n",
    "\n",
    "#### A brief note: \n",
    "As we move through the latter half of the Deep Learning module, we will be covering some of the newer, state-of-the-art models and architectures. These models become increasingly complex and require some higher-level coding insights and ability to create from scratch. As you may have noticed, implementations of LSTMs and RNNs are not on Homework 2. This doesn't mean they aren't important! \n",
    "\n",
    "This Problem Set will be largely *understanding* based - not asking as much \"coding\" questions as the previous few. Of course, as we walk through the code feel free to ask any questions about the code itself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df7d19",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf020f",
   "metadata": {},
   "source": [
    "The data from this Problem Set is the training set of [The 2012 PhysioNet/Computing in Cardiology Challenge](https://physionet.org/content/challenge-2012/1.0.0/). The goal of the challenge (and this model) is to aid in the prediction of mortaility rates in the ICU. Though the challenge offers multiple possible targets, in this code we focus on **Length of Stay** (LOS). \n",
    "\n",
    "Predicting LOS is valuable for many reasons: it aids in resource allocation and planning, helping healthcare providers allocate beds, staffing, and equipment efficiently, ensuring that critical care resources are available when needed \\[[1](https://onlinelibrary.wiley.com/doi/full/10.1111/imj.14962)\\]. LOS prediction can improve patient care and outcomes by allowing medical teams to make timely decisions regarding treatment, discharge, or transfer to lower-acuity settings \\[[2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1067452/)\\]. It can help identify patients at risk of prolonged stays, enabling interventions to prevent complications and reduce healthcare costs. Furthermore, LOS prediction can facilitate hospital management, optimize bed turnover, and reduce wait times, ultimately benefiting both patients and healthcare institutions \\[[3](https://doi.org/10.1097/MLR.0000000000001596)\\].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea92f60",
   "metadata": {},
   "source": [
    "This dataset consists of records from 4,000 ICU stays. All patients were adults and stayed for at least 48 hours. **A great deal of preprocessing has been performed on this data to make it suitable for LSTM.** The annotated scripts and notebooks for performing this preprocessing can be found on the GitHub page here (under `bonus/LSTM/preprocessing`). \n",
    "\n",
    "In order, the steps performed are:\n",
    "1. Loading the data from its original form (a large folder of csv files of the form `ID.txt`, one for each patient) into one larger csv called `patient_data.csv` containingthe columns Patient_ID, Time, Parameter, Value. (Script: `icu_data.py`)\n",
    "2. Loading this new csv and subsetting 5 of the original 37 features: SaO2, NIDiasABP, HR, Urine, PaO2\n",
    "    - These features were chosen at random\n",
    "3. Performing numerical/type conversion for the data: changing Time from the form HH:MM to \"minutes\" and ensuring all data is a native type in Python\n",
    "4. Aggregating the data - converting the columns from Patient_ID, Time, Parameter, Value to Patient_ID, Parameter, Time 0, Time 1, Time 2, ... Time 2880\n",
    "5. Selecting only patients that had measurements for *all* 5 of our features\n",
    "6. Filling the NaN values in our timepoints with backfill (and forward fill for our final timepoints).\n",
    "6. Saving as a JSON file with key/value pairs of Patient_ID/time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684444b8",
   "metadata": {},
   "source": [
    "**What issues may there be with this preprocessing, if any? How might you fix them?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574cb0ec",
   "metadata": {},
   "source": [
    "1. Feature selection randomly - how do we know we selected the right features? Why don't we use all of them? You can fix this by just using all of the features! (Or using some really awesome techniques we will learn later in the course)\n",
    "2. Backfilling the timepoints - this may not be the best way to do this. We make the implicit assumption that the value measured by the clinician at any given time was the value 1 hour after the previous measurement for a value. This is likely an incorrect assumption, and may affect our model. However, LSTM models will expect our time-series data to all be the same length. We can do other methods like padding or truncation, or use some more specialized architectures (that we will discuss next week).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d688ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc1e32",
   "metadata": {},
   "source": [
    "I have saved the patient data into a json file called `patient_data.json` (it should, if you cloned the GitHub, exist in the `data` directory relative to our current one). **Load this data into a variable called `patient_data`. Print the number of entries in this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f37d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n"
     ]
    }
   ],
   "source": [
    "with open('data/patient_data.json') as f:\n",
    "    patient_data = json.load(f)\n",
    "\n",
    "print(len(patient_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb8ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>142665</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>142667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>142670</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>142671</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>142673</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RecordID  Length_of_stay\n",
       "0       132539               5\n",
       "1       132540               8\n",
       "2       132541              19\n",
       "3       132543               9\n",
       "4       132545               4\n",
       "...        ...             ...\n",
       "3995    142665              10\n",
       "3996    142667               3\n",
       "3997    142670              11\n",
       "3998    142671               8\n",
       "3999    142673               7\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the patient outcomes (the Length of stay):\n",
    "outcomes = pd.read_csv('data/outcomes.csv')\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0696a97",
   "metadata": {},
   "source": [
    "This data has 4000 rows and 2 columns. **Is this different than the number of items in our `patient_data` variable? If so, why? How can we fix it?** (Hint: it is different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29616e",
   "metadata": {},
   "source": [
    "It is different! The outcomes csv has all 4000 of our original datapoints (the ones we had before preprocessing), so we need to remove those points that are not present in our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25095a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 5, 2881)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing the targets by removing unused IDs and preparing the features array\n",
    "## Start with two empty arrays\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "\n",
    "for patient_id in patient_data.keys():  # Recall: keys are our patient ids\n",
    "    outcome = outcomes.Length_of_stay[outcomes.RecordID == int(patient_id)]  # Take LOS where the record matches\n",
    "    feature_array = np.array(patient_data[patient_id])                       # Take features where record matches\n",
    "    # Add to our arrays\n",
    "    targets.append(int(outcome))                                        \n",
    "    features.append(feature_array)\n",
    "    \n",
    "# Convert from python lists to numpy arrays.\n",
    "features = np.array(features)\n",
    "targets = np.array(targets)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e07414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f4a27",
   "metadata": {},
   "source": [
    "The output from cell 3 shows that our feature data is 3 dimensional: 1394x5x2881. **What do each of these dimensions represent? What is the interpretaion of the value `features[0, 1, 2]`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2bf28",
   "metadata": {},
   "source": [
    "Our first dimension is our patient id (so it represents our datapoints).\n",
    "\n",
    "The second  represents our 5 selected features.\n",
    "\n",
    "The final is the time series data. \n",
    "\n",
    "Explicitly, `features[0, 1, 2]` is the 1st patient's 2nd feature (NIDiastaolABP) 3 hours after ICU arrival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de21134",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd1f83",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b1f9d",
   "metadata": {},
   "source": [
    "I will be using Pytorch's API for this Problem Set, though tensorflow will of course be somewhat similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36a54b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef44c48d10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f74de",
   "metadata": {},
   "source": [
    "Looking ahead at the documentation, I noticed that torch's LSTM module expects data to be in the form $\\left(\\textrm{Number of Participants} \\times \\textrm{Sequence Length} \\times \\textrm{Number of Features}\\right)$. \n",
    "\n",
    "**Create a variable `X` with the type `torch.Tensor`, and use the Tensor method `permute` to change the dimensions.\n",
    "Verify that the shape has changed by printing off `X.shape`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2649e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1394, 2881, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(features).permute(0, 2, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62804c7f",
   "metadata": {},
   "source": [
    "Y is already the right shape, so I'll just convert that to a Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b34b3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1394])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor(targets)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb35555",
   "metadata": {},
   "source": [
    "Of course, we need to split the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c659606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84a889",
   "metadata": {},
   "source": [
    "### Defining an LSTM model.\n",
    "\n",
    "PyTorch has implemented an LSTM layer so we don't have to do a lot of the hard work. We have a bit of Object Oriented Programming ahead with the class definition. \n",
    "\n",
    "As a reminder from our intro to python, the `class` in python contains a collection of functions and values of our choosing. When creating a class, we can specifiy and access these values through the `self` variable given to each class function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52b8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    # The method that is called when an object is created with this class\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        # Start with pytorch's model initialization - this is called Superclassing\n",
    "        super().__init__() \n",
    "        \n",
    "        # Use our passed parameters to create a class variable lstm\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # One fully connected layer that takes our output of the LSTM and produces a prediction\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        \n",
    "    # The method that is called when we do the \"foward pass\" of our model: features in -> predictions out\n",
    "    def forward(self, x):\n",
    "        # LSTM layers return a tuple, and we only care about the output of the layer.\n",
    "        out, _ = self.lstm(x)  # The _ is pythons way of ignoring an output. \n",
    "        \n",
    "        out = out[:, -1, :]  # Take the last value in the output of our LSTM (the output of the last \"block\")\n",
    "        out = self.fc(out)   # Pass though our FC layer\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a091d4",
   "metadata": {},
   "source": [
    "In our forward pass, we \"throw out\" the second part of a tuple returned by the LSTM layer. Looking at the documentation, we are throwing out two variables (joined in a tuple) called `h_n` and `c_n`. **Using your knowledge of the components of LSTM, what is this part we are throwing out?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdddb",
   "metadata": {},
   "source": [
    "The hidden states and the cell states for each element in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea7bad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d74f6",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6e63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5         # Number of features in\n",
    "hidden_size = 64       # Number of output neurons for our LSTM model\n",
    "num_layers = 2         # How many LSTM layers to add \n",
    "output_size = 1        # Number of features out\n",
    "learning_rate = 0.001  # How fast the model trains\n",
    "num_epochs = 10        # How many times to loop through the training data      \n",
    "batch_size = 32        # How many training samples to work through before updating our weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15961e4c",
   "metadata": {},
   "source": [
    "Which of these can we change? Which are dependent on our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e651a",
   "metadata": {},
   "source": [
    "We cannot change: \n",
    "- Input Size\n",
    "- Output Size\n",
    "\n",
    "We can change the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e41b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39105b88",
   "metadata": {},
   "source": [
    "### Preparing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e304779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)  # Instance of our defined class!\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41e1f5",
   "metadata": {},
   "source": [
    "#### Datasets and Dataloaders:\n",
    "Datasets and Dataloaders are pytorch's optimized way of loading in data. Though generally unnecessary for the class, those of you with a desire to implement some of the more advanced ML algorithms in your own projects may benefit from this efficiency. Generally speaking, a Dataset will \"pair up\" your input features and targets and provide instructions for loading it into memory (either VRAM on a GPU or RAM on a CPU) and a DataLoader will allow you to access the data in batches using python's `in` syntax. In more advanced applications when you want to perform augmentation to your data, you can do so in the DataLoader through the `transforms` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f479fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc61d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 341.7469530378069\n",
      "Epoch [2/10], Loss: 242.93503821236746\n",
      "Epoch [3/10], Loss: 208.13684539794923\n",
      "Epoch [4/10], Loss: 195.3608488900321\n",
      "Epoch [5/10], Loss: 187.02174181256976\n",
      "Epoch [6/10], Loss: 184.56531241280692\n",
      "Epoch [7/10], Loss: 185.93643362862724\n",
      "Epoch [8/10], Loss: 183.01782684326173\n",
      "Epoch [9/10], Loss: 183.61430086408342\n",
      "Epoch [10/10], Loss: 183.7209159851074\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "epochs = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, targets.view(-1, 1))  # Reshape targets to the same shape as our output\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update our loss. loss.item() extracts the actual value of our loss (as a float)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the current epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader)}')\n",
    "    losses.append(total_loss/len(train_loader))\n",
    "    epochs.append(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b745db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 141.84146118164062\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass on the test data\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "\n",
    "# Calculate the loss (MSE)\n",
    "criterion = nn.MSELoss()\n",
    "test_loss = criterion(test_outputs, y_test.view(-1, 1))  # Reshape y_test like in our training loop\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_outputs = test_outputs.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "\n",
    "# Print or return the test loss\n",
    "print(f'Test Loss (MSE): {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced6d68",
   "metadata": {},
   "source": [
    "**Evauluate the model. Besides MSE, what are some other metrics, plots, or methods we may want to calculate/implement to evaluate our model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d9817",
   "metadata": {},
   "source": [
    "The model performs well relatively on the training set but even better on our test set? Surely this is an error, right? Not necessarily! Though we would expect our model to perform better on the test set, we may have randomly selected a testing set that is easier for our model to predict. Let's investigate by looking at our test_outputs and y_test (below). Sure enough, our model basically just predicts the number \"13\" with very little deviation, and our test set has more values close to 13. We can fix this by increasing learning rate, adding more features in (recall we only had 5 features and performed *heavy* imputation), or adding in more data! \n",
    "\n",
    "\n",
    "RMSE, MAE, R-Squared are all good metrics, we may also want to implement *validation*, either cross-validation or regular. We can then plot the training vs validation accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "085fb7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.468479 ],\n",
       "       [13.397302 ],\n",
       "       [13.251711 ],\n",
       "       [13.4583   ],\n",
       "       [13.367361 ],\n",
       "       [13.286934 ],\n",
       "       [13.3590145],\n",
       "       [13.402573 ],\n",
       "       [13.461424 ],\n",
       "       [13.341604 ],\n",
       "       [13.351273 ],\n",
       "       [13.405039 ],\n",
       "       [13.396328 ],\n",
       "       [13.105703 ],\n",
       "       [13.441333 ],\n",
       "       [13.211384 ],\n",
       "       [13.350622 ],\n",
       "       [13.404208 ],\n",
       "       [13.474545 ],\n",
       "       [13.391685 ],\n",
       "       [13.238646 ],\n",
       "       [13.377986 ],\n",
       "       [13.282976 ],\n",
       "       [13.392442 ],\n",
       "       [13.407609 ],\n",
       "       [13.412725 ],\n",
       "       [13.292026 ],\n",
       "       [13.355558 ],\n",
       "       [13.527838 ],\n",
       "       [13.3892145],\n",
       "       [13.387373 ],\n",
       "       [13.390233 ],\n",
       "       [13.301243 ],\n",
       "       [13.251772 ],\n",
       "       [13.409026 ],\n",
       "       [13.530205 ],\n",
       "       [13.324175 ],\n",
       "       [13.315826 ],\n",
       "       [13.54294  ],\n",
       "       [13.637739 ],\n",
       "       [13.475727 ],\n",
       "       [13.262101 ],\n",
       "       [13.186493 ],\n",
       "       [13.418828 ],\n",
       "       [13.368014 ],\n",
       "       [13.507646 ],\n",
       "       [13.435593 ],\n",
       "       [13.200752 ],\n",
       "       [13.628298 ],\n",
       "       [13.360608 ],\n",
       "       [13.217518 ],\n",
       "       [13.213596 ],\n",
       "       [13.391504 ],\n",
       "       [13.278424 ],\n",
       "       [13.333868 ],\n",
       "       [13.345396 ],\n",
       "       [13.266258 ],\n",
       "       [13.289228 ],\n",
       "       [13.330409 ],\n",
       "       [13.497881 ],\n",
       "       [13.519201 ],\n",
       "       [13.349213 ],\n",
       "       [13.155916 ],\n",
       "       [13.399012 ],\n",
       "       [13.370359 ],\n",
       "       [13.318105 ],\n",
       "       [13.485163 ],\n",
       "       [13.378685 ],\n",
       "       [13.232335 ],\n",
       "       [13.391651 ],\n",
       "       [13.341239 ],\n",
       "       [13.700962 ],\n",
       "       [13.32316  ],\n",
       "       [13.421265 ],\n",
       "       [13.482672 ],\n",
       "       [13.413628 ],\n",
       "       [13.343455 ],\n",
       "       [13.317593 ],\n",
       "       [13.300188 ],\n",
       "       [13.43331  ],\n",
       "       [13.429591 ],\n",
       "       [13.376453 ],\n",
       "       [13.3269005],\n",
       "       [13.370365 ],\n",
       "       [13.293092 ],\n",
       "       [13.305319 ],\n",
       "       [13.309763 ],\n",
       "       [13.2215185],\n",
       "       [13.345242 ],\n",
       "       [13.388782 ],\n",
       "       [13.587249 ],\n",
       "       [13.356167 ],\n",
       "       [13.126638 ],\n",
       "       [13.395081 ],\n",
       "       [13.294849 ],\n",
       "       [13.443524 ],\n",
       "       [13.237036 ],\n",
       "       [13.396221 ],\n",
       "       [13.248314 ],\n",
       "       [13.302616 ],\n",
       "       [13.457249 ],\n",
       "       [13.330941 ],\n",
       "       [13.523975 ],\n",
       "       [13.356871 ],\n",
       "       [13.413184 ],\n",
       "       [13.313705 ],\n",
       "       [13.335823 ],\n",
       "       [13.25667  ],\n",
       "       [13.362804 ],\n",
       "       [13.210161 ],\n",
       "       [13.370228 ],\n",
       "       [13.233387 ],\n",
       "       [13.290329 ],\n",
       "       [13.357784 ],\n",
       "       [13.310692 ],\n",
       "       [13.243252 ],\n",
       "       [13.383194 ],\n",
       "       [13.556316 ],\n",
       "       [13.440657 ],\n",
       "       [13.3927   ],\n",
       "       [13.292446 ],\n",
       "       [13.501694 ],\n",
       "       [13.507792 ],\n",
       "       [13.263622 ],\n",
       "       [13.299089 ],\n",
       "       [13.405912 ],\n",
       "       [13.325772 ],\n",
       "       [13.08817  ],\n",
       "       [13.385812 ],\n",
       "       [13.385119 ],\n",
       "       [13.386068 ],\n",
       "       [13.354285 ],\n",
       "       [13.314283 ],\n",
       "       [13.335131 ],\n",
       "       [13.440044 ],\n",
       "       [13.272322 ],\n",
       "       [13.56716  ],\n",
       "       [13.285515 ],\n",
       "       [12.972271 ],\n",
       "       [13.286338 ],\n",
       "       [13.344588 ],\n",
       "       [13.297455 ],\n",
       "       [13.348236 ],\n",
       "       [13.165548 ],\n",
       "       [13.268291 ],\n",
       "       [13.305162 ],\n",
       "       [13.343646 ],\n",
       "       [13.423863 ],\n",
       "       [13.41943  ],\n",
       "       [13.413965 ],\n",
       "       [13.384602 ],\n",
       "       [13.422062 ],\n",
       "       [13.324419 ],\n",
       "       [13.52844  ],\n",
       "       [13.387145 ],\n",
       "       [13.509579 ],\n",
       "       [13.386587 ],\n",
       "       [13.237326 ],\n",
       "       [13.360422 ],\n",
       "       [13.497599 ],\n",
       "       [13.1633215],\n",
       "       [13.418304 ],\n",
       "       [13.41163  ],\n",
       "       [13.36508  ],\n",
       "       [13.361609 ],\n",
       "       [13.451395 ],\n",
       "       [13.2779045],\n",
       "       [13.287018 ],\n",
       "       [13.415574 ],\n",
       "       [13.261552 ],\n",
       "       [13.176548 ],\n",
       "       [13.445179 ],\n",
       "       [13.290036 ],\n",
       "       [13.328264 ],\n",
       "       [13.6912155],\n",
       "       [13.341144 ],\n",
       "       [13.282934 ],\n",
       "       [13.29756  ],\n",
       "       [13.262769 ],\n",
       "       [13.536217 ],\n",
       "       [13.2673435],\n",
       "       [13.401795 ],\n",
       "       [13.591435 ],\n",
       "       [13.34124  ],\n",
       "       [13.36136  ],\n",
       "       [13.415456 ],\n",
       "       [13.438299 ],\n",
       "       [13.341431 ],\n",
       "       [13.588319 ],\n",
       "       [13.426489 ],\n",
       "       [13.330382 ],\n",
       "       [13.513567 ],\n",
       "       [13.296091 ],\n",
       "       [13.421986 ],\n",
       "       [13.733715 ],\n",
       "       [13.353662 ],\n",
       "       [13.094311 ],\n",
       "       [13.264145 ],\n",
       "       [13.55226  ],\n",
       "       [13.212142 ],\n",
       "       [13.435639 ],\n",
       "       [13.097431 ],\n",
       "       [13.355966 ],\n",
       "       [13.422266 ],\n",
       "       [13.339116 ],\n",
       "       [13.32913  ],\n",
       "       [13.280317 ],\n",
       "       [13.363784 ],\n",
       "       [13.145706 ],\n",
       "       [13.266182 ],\n",
       "       [13.407326 ],\n",
       "       [13.280027 ],\n",
       "       [13.6058655],\n",
       "       [13.550602 ],\n",
       "       [13.372799 ],\n",
       "       [13.247853 ],\n",
       "       [13.338648 ],\n",
       "       [13.435546 ],\n",
       "       [13.391357 ],\n",
       "       [13.290582 ],\n",
       "       [13.403864 ],\n",
       "       [13.455857 ],\n",
       "       [13.305716 ],\n",
       "       [13.388334 ],\n",
       "       [13.377606 ],\n",
       "       [13.319598 ],\n",
       "       [13.279053 ],\n",
       "       [13.37854  ],\n",
       "       [13.284325 ],\n",
       "       [13.402452 ],\n",
       "       [13.35289  ],\n",
       "       [13.455713 ],\n",
       "       [13.365702 ],\n",
       "       [13.558737 ],\n",
       "       [13.182589 ],\n",
       "       [13.157946 ],\n",
       "       [13.4235115],\n",
       "       [13.320708 ],\n",
       "       [13.22866  ],\n",
       "       [13.243886 ],\n",
       "       [13.278931 ],\n",
       "       [13.628513 ],\n",
       "       [13.323188 ],\n",
       "       [13.404798 ],\n",
       "       [13.359151 ],\n",
       "       [13.334729 ],\n",
       "       [13.37555  ],\n",
       "       [13.394136 ],\n",
       "       [13.449422 ],\n",
       "       [13.365009 ],\n",
       "       [13.35729  ],\n",
       "       [13.172015 ],\n",
       "       [13.234137 ],\n",
       "       [13.328777 ],\n",
       "       [13.451792 ],\n",
       "       [13.358317 ],\n",
       "       [13.545957 ],\n",
       "       [13.273844 ],\n",
       "       [13.427172 ],\n",
       "       [13.311156 ],\n",
       "       [13.277295 ],\n",
       "       [13.216641 ],\n",
       "       [13.537304 ],\n",
       "       [13.41463  ],\n",
       "       [13.347679 ],\n",
       "       [13.419184 ],\n",
       "       [13.31333  ],\n",
       "       [13.417321 ],\n",
       "       [13.346596 ],\n",
       "       [13.374674 ],\n",
       "       [13.293597 ],\n",
       "       [13.311485 ],\n",
       "       [13.380526 ],\n",
       "       [13.436157 ],\n",
       "       [13.407305 ],\n",
       "       [13.481248 ],\n",
       "       [13.110012 ],\n",
       "       [13.433368 ],\n",
       "       [13.391479 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926e33d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5., 20.,  9., 16., 10.,  9.,  4., 13.,  6.,  7., 12., 15.,\n",
       "       39., 15., 11.,  7., 10., 17.,  5., 14.,  8.,  3.,  7.,  6., 17.,\n",
       "        8., 19., 12.,  9., 19.,  5.,  5.,  5., 15.,  5., 12., 15.,  4.,\n",
       "       22., 10., 11.,  9., 18.,  9., 12.,  8., 11.,  7., 21.,  6., 31.,\n",
       "       33.,  6., 12., 53., 22., 16.,  6., 13.,  5., 14.,  8., 11., 12.,\n",
       "       25., 14., 10.,  8., 15., 30.,  6.,  8., 25., 66., 15., 14.,  2.,\n",
       "       40., 10., 12., 33.,  9.,  6.,  7.,  7., 84., 27.,  9., 11., 30.,\n",
       "        7.,  8., 11.,  6., 11., 13., 13., 64.,  5., 18.,  8., 12.,  8.,\n",
       "       12., 18.,  9., 16., 16.,  6.,  5., 22.,  6.,  6., 17.,  7.,  4.,\n",
       "        6., 13., 43., 18.,  6.,  9., 12., 42.,  9., 32., 21.,  5., 31.,\n",
       "       11.,  5., 18.,  6., 25., 10., 22., 11., 28., 18., 11.,  5., 13.,\n",
       "       10., 51.,  7., 19.,  5., -1.,  5., 43., 24., 13.,  5.,  9., 14.,\n",
       "        8.,  8.,  2.,  4., 13., 10.,  6.,  7.,  8., 22.,  5.,  5., 32.,\n",
       "        4., 46., 18., 11.,  5.,  5., 20.,  8., 29.,  3., 24.,  5.,  7.,\n",
       "        8., 51., 15., 60., 22.,  7.,  8., 15., 12., 15.,  4.,  5.,  9.,\n",
       "       21., 44.,  6.,  7., 10., 13.,  7., 17., 10., 10., 13., 10., 11.,\n",
       "        5.,  8.,  6.,  6., 10., 34., 10., 20., 14.,  7., 24., 12.,  8.,\n",
       "       20.,  6., 48.,  5., 12., 13., 28., 10., 20.,  9.,  9., 11., 11.,\n",
       "       13., -1., 18., 12., 13., 27., 12., 47., 13., 33., 10.,  4.,  4.,\n",
       "       15.,  7., 27.,  9., 14., 13., 10.,  4., 20.,  6.,  6., 10.,  7.,\n",
       "        8.,  8.,  8., 11., 10.,  5., 37.,  6.,  3.,  8.,  2., 24., 11.,\n",
       "        7.,  7.,  9., 16., 10., 21.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5761b8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
